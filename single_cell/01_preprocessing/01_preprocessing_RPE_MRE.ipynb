{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5b54276-7caa-44df-ad01-d6d865896dc9",
   "metadata": {},
   "source": [
    "# 01 Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67b89c-9758-4d40-8ab9-1ec3eccbed6c",
   "metadata": {},
   "source": [
    "## Initialize Environment\n",
    "First import all the necessary packages here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422fb019-981c-4aa9-be37-421f2f785614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import os\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import seaborn as sns\n",
    "import scanpy.external as sce\n",
    "import matplotlib.pyplot as pl\n",
    "import anndata2ri\n",
    "import logging\n",
    "\n",
    "from matplotlib import colors\n",
    "from datetime import datetime as dt\n",
    "from scipy.stats import median_abs_deviation\n",
    "\n",
    "# Scanpy settings\n",
    "sc.settings.verbosity = 3\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a9c0dc-9705-4163-b606-5a4b2e811997",
   "metadata": {},
   "source": [
    "Identify the starting directory. Get a timestamp for the run. From the timestamp, derive the resulting output h5ad filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00808649-d825-4bd0-b364-df7d9bdb671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name Variables and Settings\n",
    "fn = \"01_\"                              # Filename Prefix\n",
    "sf = \"_preprocessing\"                   # Filename Suffix\n",
    "experiment = \"Runx3-mut\"                # Experiment batch\n",
    "savedata = True                         # Save data at the end\n",
    "\n",
    "# Set working directory\n",
    "os.chdir(\"/home/dalbao/2023-012-Runx3mutD8scRNA/AlbaoRunx3Manuscript/single_cell/01_preprocessing\")\n",
    "\n",
    "# Determine work location\n",
    "print(\"The work location for this notebook is: \" + os.getcwd() + \"\\n\")\n",
    "\n",
    "# Get a timestamp for the start of the run\n",
    "timestamp = dt.now()\n",
    "print(\"This notebook was last run on \" + timestamp.strftime(\"%y-%m-%d %H:%M\"))\n",
    "\n",
    "# Determine the filename for the expected output h5ad\n",
    "fn = fn + timestamp.strftime(\"%y-%m-%d-%H-%M\")\n",
    "print(\"The filename for the AnnData output of this notebook will be:\")\n",
    "print(fn + sf + \"_{RPE|MRE}.h5ad\")\n",
    "print(\"which will be saved in the WORKDIR/h5ad/ folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521d46bf-5443-49bb-a4f2-cce91ff122db",
   "metadata": {},
   "source": [
    "The work directory is structured to contain a folder named \"outs\" which itself contains output from the Cell Ranger multi pipeline. \"outs\" contains demultiplexed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86bd50a-d6c6-4194-a999-073c0d14e964",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_pre= \"../../source_data/gem\"\n",
    "sd_post = \"/outs/per_sample_outs\"\n",
    "\n",
    "# Path to look inside\n",
    "target_dir = sd_pre + \"1\" + sd_post\n",
    "\n",
    "# List **only folders**\n",
    "sample_names = [\n",
    "    d for d in os.listdir(target_dir)\n",
    "    if os.path.isdir(os.path.join(target_dir, d))\n",
    "]\n",
    "sample_names.sort()\n",
    "print(sample_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3710e4-bdb4-49d8-8a27-060c3fa94fa2",
   "metadata": {},
   "source": [
    "Go through all the samples in sample_names and then load the data into a new object in Python. This differs from the tutorial in that the different samples which were multiplexed will be loaded and initially pre-processed seprately before concatenating them and performing normalization.\n",
    "\n",
    "Make one list per GEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6171071-25d7-4c5c-a3d2-f6e009a7ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples1 = [] # Array to contain the AnnData for each of the individual groups\n",
    "samples2 = [] # Array to contain the AnnData for each of the individual groups\n",
    "\n",
    "### MANUAL ANNOTATION\n",
    "infection = [\"Arm\", \"Naive\", \"Arm\", \"Arm\", \"Arm\", \"Arm\", \"Arm\", \"Arm\", \"Arm\"]\n",
    "timepoint = [\"Day 8\", \"Naive\", \"Day 8\", \"Day 8\", \"Day 5\", \"Day 8\", \"Day 8\", \"Day 8\", \"Day 8\"]\n",
    "\n",
    "# Loop through all samples in sample_names for sample1\n",
    "for index in range(0, len(sample_names)):\n",
    "    \n",
    "    # Load samples individually into each array element\n",
    "    samples1.append(sc.read_10x_mtx(sd_pre +\n",
    "                                    \"1\" + \n",
    "                                    sd_post +\n",
    "                                    \"/\" + \n",
    "                                    sample_names[index] + \n",
    "                                    \"/count/sample_filtered_feature_bc_matrix\"))\n",
    "\n",
    "    # Annotate each sample with the experiment as a group observation\n",
    "    samples1[index].obs[\"experiment\"] = experiment\n",
    "    # Annotate each sample with the sample name as a group observation\n",
    "    samples1[index].obs[\"group\"] = sample_names[index]\n",
    "    # Annotate each sample with the timepoint as a group observation\n",
    "    samples1[index].obs[\"timepoint\"] = infection[index]\n",
    "    # Annotate each sample with the infection as a group observation\n",
    "    samples1[index].obs[\"infection\"] = timepoint[index]\n",
    "    # Check output\n",
    "    samples1[index]\n",
    "# End loop\n",
    "\n",
    "del(index) # Cleanup\n",
    "\n",
    "# Loop through all samples in sample_names for sample1\n",
    "for index in range(0, len(sample_names)):\n",
    "    \n",
    "    # Load samples individually into each array element\n",
    "    samples2.append(sc.read_10x_mtx(sd_pre +\n",
    "                                    \"2\" + \n",
    "                                    sd_post + \n",
    "                                    \"/\" + \n",
    "                                    sample_names[index] + \n",
    "                                    \"/count/sample_filtered_feature_bc_matrix\"))\n",
    "\n",
    "    # Annotate each sample with the experiment as a group observation\n",
    "    samples2[index].obs[\"experiment\"] = experiment\n",
    "    # Annotate each sample with the sample name as a group observation\n",
    "    samples2[index].obs[\"group\"] = sample_names[index]\n",
    "    # Annotate each sample with the timepoint as a group observation\n",
    "    samples2[index].obs[\"timepoint\"] = infection[index]\n",
    "    # Annotate each sample with the infection as a group observation\n",
    "    samples2[index].obs[\"infection\"] = timepoint[index]\n",
    "    # Check output\n",
    "    samples2[index]\n",
    "# End loop\n",
    "\n",
    "del(index) # Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3fdf53-ed50-48cb-aaef-065b75e0579d",
   "metadata": {},
   "source": [
    "Then combine all hashtagged samples into one adata file per GEM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee8bb58-d35f-4700-8730-b305c378cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the first element in the array as the base\n",
    "adata1 = samples1[0]\n",
    "\n",
    "# Concatenate sample on top of the base\n",
    "# Start from sample 1, since adata already contains sample 0 \n",
    "for index in range(1, len(sample_names)):\n",
    "    adata1 = ad.concat([adata1, samples1[index]], join = \"outer\") # Outer option does a union of all genes\n",
    "# End loop\n",
    "\n",
    "# Confirm resulting AnnData file then cleanup\n",
    "print(adata1)\n",
    "del(samples1, index)\n",
    "\n",
    "# Set the first element in the array as the base\n",
    "adata2 = samples2[0]\n",
    "\n",
    "# Concatenate sample on top of the base\n",
    "# Start from sample 1, since adata already contains sample 0 \n",
    "for index in range(1, len(sample_names)):\n",
    "    adata2 = ad.concat([adata2, samples2[index]], join = \"outer\") # Outer option does a union of all genes\n",
    "# End loop\n",
    "\n",
    "# Confirm resulting AnnData file then cleanup\n",
    "print(adata2)\n",
    "del(samples2, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81616ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make cell_id column\n",
    "adata1.obs['cell_id'] = adata1.obs.index.astype(str)\n",
    "adata2.obs['cell_id'] = adata2.obs.index.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f05fad-5617-4951-b2b4-26bf6bb177eb",
   "metadata": {},
   "source": [
    "## Basic pre-processing\n",
    "\n",
    "For basic quality control metrics, plot the highest expressed genes per sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b46ccf-40d7-4a87-82dd-33b1d905c4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata1\n",
    "# Plot highest expressed genes per sample\n",
    "for group in sample_names:\n",
    "    \n",
    "    plot = sc.pl.highest_expr_genes(adata1[adata1.obs.group == group, :], n_top=20, show = False)\n",
    "    plot.set_title(group + \" GEM1 Pre-clean\")\n",
    "# End of loop\n",
    "\n",
    "del(plot) # Cleanup``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58f0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata2\n",
    "# Plot highest expressed genes per sample\n",
    "for group in sample_names:\n",
    "    \n",
    "    plot = sc.pl.highest_expr_genes(adata2[adata2.obs.group == group, :], n_top=20, show = False)\n",
    "    plot.set_title(group  + \" GEM2 Pre-clean\")\n",
    "# End of loop\n",
    "\n",
    "del(plot) # Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7e9800-115a-4bf8-acc5-501dd3d64c42",
   "metadata": {},
   "source": [
    "## Filtering\n",
    "\n",
    "Create filters for outliers based on counts and number of genes expressed and filter genes based on number of cells or counts.\n",
    "\n",
    "But first, check the original metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3c9b8-f338-407f-ad2a-b776be1cbc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adata1)\n",
    "print(adata2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafd2e5-ae83-4d67-8006-1f45ca22ad56",
   "metadata": {},
   "source": [
    "Compute quality metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737593e8-7ebd-4711-bd92-f02277a7dca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata1\n",
    "# Mitochondrial genes\n",
    "adata1.var[\"mt\"] = adata1.var_names.str.startswith(\"mt-\")\n",
    "# Ribosomal genes\n",
    "adata1.var[\"ribo\"] = adata1.var_names.str.startswith((\"Rps\", \"Rpl\"))\n",
    "\n",
    "# Calculate percent mitochondrial gene contamination\n",
    "sc.pp.calculate_qc_metrics(adata1, qc_vars=['mt', 'ribo'], percent_top=None, log1p=True, inplace=True)\n",
    "\n",
    "# Plot quality metrics:\n",
    "\n",
    "sc.pl.violin(adata1, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], groupby= \"group\", jitter=0.4, multi_panel=True)\n",
    "for group in sample_names:\n",
    "    \n",
    "    sc.pl.scatter(adata1[adata1.obs.group == group, :], x='total_counts', y='pct_counts_mt', title = \"Pre-filter GEM1 \"+group)\n",
    "    sc.pl.scatter(adata1[adata1.obs.group == group, :], x='total_counts', y='n_genes_by_counts', title = \"Pre-filter GEM1 \"+group)\n",
    "# End of loop\n",
    "\n",
    "del(group) # Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ceab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata2\n",
    "# Mitochondrial genes\n",
    "adata2.var[\"mt\"] = adata2.var_names.str.startswith(\"mt-\")\n",
    "# Ribosomal genes\n",
    "adata2.var[\"ribo\"] = adata2.var_names.str.startswith((\"Rps\", \"Rpl\"))\n",
    "\n",
    "# Calculate percent mitochondrial gene contamination\n",
    "sc.pp.calculate_qc_metrics(adata2, qc_vars=['mt', 'ribo'], percent_top=None, log1p=True, inplace=True,)\n",
    "\n",
    "# Plot quality metrics:\n",
    "\n",
    "sc.pl.violin(adata2, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], groupby= \"group\", jitter=0.4, multi_panel=True)\n",
    "for group in sample_names:\n",
    "    \n",
    "    sc.pl.scatter(adata2[adata2.obs.group == group, :], x='total_counts', y='pct_counts_mt', title = \"Pre-filter GEM2 \"+group)\n",
    "    sc.pl.scatter(adata2[adata2.obs.group == group, :], x='total_counts', y='n_genes_by_counts', title = \"Pre-filter GEM2 \"+group)\n",
    "# End of loop\n",
    "\n",
    "del(group) # Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404e003b-b44d-4287-8dcd-a49d935ec8cc",
   "metadata": {},
   "source": [
    "Now for each sample in the array \"samples\" do the following:\n",
    "\n",
    "1) Correct for ambient RNA.\n",
    "2) Do doublet discrimination with scrublet and scDblFinder and mark doublets, but do not filter yet!\n",
    "3) Create low-level filters.\n",
    "4) High-level filtering:\n",
    " - remove cells with less than 200 genes\n",
    " - genes expressed in less than 3 cells\n",
    " - genes with less than 5 counts\n",
    "5) Do low level filtering by removing high MT contamination, doublets and low counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5d30b-0a2a-4f9a-a333-bcfb49d9e219",
   "metadata": {},
   "source": [
    "### Ambient RNA correction on GEM1\n",
    "\n",
    "First import packages to run R on the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac2581-6176-485a-b2c7-982ae037a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.rinterface_lib.callbacks as rcb\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "rcb.logger.setLevel(logging.ERROR)\n",
    "ro.pandas2ri.activate()\n",
    "anndata2ri.activate()\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243c9f6d-5fc4-4b7d-b7b2-b6143afe1a36",
   "metadata": {},
   "source": [
    "SoupX requires basic clustering data and raw data, so do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1601bdf8-afa9-42ae-80a3-5cca5616a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make adata copy then normalize\n",
    "adata_pp = adata1.copy()\n",
    "sc.pp.normalize_per_cell(adata_pp)\n",
    "sc.pp.log1p(adata_pp)\n",
    "\n",
    "# Do dimensionality reduction\n",
    "sc.pp.pca(adata_pp)\n",
    "sc.pp.neighbors(adata_pp)\n",
    "sc.tl.leiden(adata_pp, key_added=\"soupx_groups\")\n",
    "\n",
    "# Extract groups\n",
    "soupx_groups = adata_pp.obs[\"soupx_groups\"]\n",
    "\n",
    "# Cleanup, remove extra adata\n",
    "del adata_pp\n",
    "\n",
    "# Prepare data for SoupX\n",
    "cells = adata1.obs_names\n",
    "genes = adata1.var_names\n",
    "data = adata1.X.T\n",
    "\n",
    "# Import raw data needed for SoupX\n",
    "adata_raw = sc.read_10x_h5(filename=\"../../source_data/gem1/outs/multi/count/raw_feature_bc_matrix.h5\")\n",
    "adata_raw.var_names_make_unique()\n",
    "data_tod = adata_raw.X.T\n",
    "del adata_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71988e50-cd89-4395-ae4c-76fb41274560",
   "metadata": {},
   "source": [
    "Call the R function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf22bb95-5d50-45c9-83dc-aa31176cd11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out \n",
    "library(SoupX)\n",
    "\n",
    "# specify row and column names of data\n",
    "rownames(data) = genes\n",
    "colnames(data) = cells\n",
    "# ensure correct sparse format for table of counts and table of droplets\n",
    "data <- as(data, \"sparseMatrix\")\n",
    "data_tod <- as(data_tod, \"sparseMatrix\")\n",
    "\n",
    "# Generate SoupChannel Object for SoupX \n",
    "sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n",
    "\n",
    "# Add extra meta data to the SoupChannel object\n",
    "soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\n",
    "sc = setSoupProfile(sc, soupProf)\n",
    "# Set cluster information in SboupChannel\n",
    "sc = setClusters(sc, soupx_groups)\n",
    "\n",
    "# Estimate contamination fraction\n",
    "sc  = autoEstCont(sc, doPlot=FALSE)\n",
    "# Infer corrected table of counts and rount to integer\n",
    "out = adjustCounts(sc, roundToInt = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2bac99-6a29-4014-bc8f-ff5943067051",
   "metadata": {},
   "source": [
    "Take the outputs from R and reassign to adata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e291f633-20d5-4f0a-aeae-8af5094b4b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata1.layers[\"counts\"] = adata1.X\n",
    "adata1.layers[\"soupX_counts\"] = out.T\n",
    "adata1.X = adata1.layers[\"soupX_counts\"]\n",
    "\n",
    "# Cleanup\n",
    "del(out, data, data_tod, genes, cells, soupx_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9419059",
   "metadata": {},
   "source": [
    "### Ambient RNA correction on GEM2\n",
    "\n",
    "First import packages to run R on the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.rinterface_lib.callbacks as rcb\n",
    "import rpy2.robjects as ro\n",
    "\n",
    "rcb.logger.setLevel(logging.ERROR)\n",
    "ro.pandas2ri.activate()\n",
    "anndata2ri.activate()\n",
    "\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d00b9",
   "metadata": {},
   "source": [
    "SoupX requires basic clustering data and raw data, so do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make adata copy then normalize\n",
    "adata_pp = adata2.copy()\n",
    "sc.pp.normalize_per_cell(adata_pp)\n",
    "sc.pp.log1p(adata_pp)\n",
    "\n",
    "# Do dimensionality reduction\n",
    "sc.pp.pca(adata_pp)\n",
    "sc.pp.neighbors(adata_pp)\n",
    "sc.tl.leiden(adata_pp, key_added=\"soupx_groups\")\n",
    "\n",
    "# Extract groups\n",
    "soupx_groups = adata_pp.obs[\"soupx_groups\"]\n",
    "\n",
    "# Cleanup, remove extra adata\n",
    "del adata_pp\n",
    "\n",
    "# Prepare data for SoupX\n",
    "cells = adata2.obs_names\n",
    "genes = adata2.var_names\n",
    "data = adata2.X.T\n",
    "\n",
    "# Import raw data needed for SoupX\n",
    "adata_raw = sc.read_10x_h5(filename=\"../../source_data/gem2/outs/multi/count/raw_feature_bc_matrix.h5\")\n",
    "adata_raw.var_names_make_unique()\n",
    "data_tod = adata_raw.X.T\n",
    "del adata_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799470c",
   "metadata": {},
   "source": [
    "Call the R function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out \n",
    "library(SoupX)\n",
    "\n",
    "# specify row and column names of data\n",
    "rownames(data) = genes\n",
    "colnames(data) = cells\n",
    "# ensure correct sparse format for table of counts and table of droplets\n",
    "data <- as(data, \"sparseMatrix\")\n",
    "data_tod <- as(data_tod, \"sparseMatrix\")\n",
    "\n",
    "# Generate SoupChannel Object for SoupX \n",
    "sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE)\n",
    "\n",
    "# Add extra meta data to the SoupChannel object\n",
    "soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data))\n",
    "sc = setSoupProfile(sc, soupProf)\n",
    "# Set cluster information in SboupChannel\n",
    "sc = setClusters(sc, soupx_groups)\n",
    "\n",
    "# Estimate contamination fraction\n",
    "sc  = autoEstCont(sc, doPlot=FALSE)\n",
    "# Infer corrected table of counts and rount to integer\n",
    "out = adjustCounts(sc, roundToInt = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182dedd3",
   "metadata": {},
   "source": [
    "Take the outputs from R and reassign to adata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3c735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata2.layers[\"counts\"] = adata2.X\n",
    "adata2.layers[\"soupX_counts\"] = out.T\n",
    "adata2.X = adata2.layers[\"soupX_counts\"]\n",
    "\n",
    "# Cleanup\n",
    "del(out, data, data_tod, genes, cells, soupx_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270141bc-3d0c-4401-bfce-1808abb51fc3",
   "metadata": {},
   "source": [
    "### Doublet Discrimination\n",
    "\n",
    "Analyze using scrublet and scDblFinder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7b0ad-b143-4acd-9b30-da7f15d73417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublet discrimination with scrublet\n",
    "sce.pp.scrublet(\n",
    "    adata1,\n",
    "    adata_sim = None,\n",
    "    threshold=0.25,\n",
    ")\n",
    "%matplotlib inline\n",
    "sce.pl.scrublet_score_distribution(adata1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfcb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublet discrimination with scrublet\n",
    "sce.pp.scrublet(\n",
    "    adata2,\n",
    "    adata_sim = None,\n",
    "    threshold=0.25,\n",
    ")\n",
    "sce.pl.scrublet_score_distribution(adata2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64aad81-5d11-445f-850c-db120e21282f",
   "metadata": {},
   "source": [
    "Do another doublet discrimination technique using scDblDinder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b1ed38-5e75-4405-a0db-5df39a056fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublet discrimination by scDblFinder\n",
    "# First extract matrix:\n",
    "data_mat = adata1.X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa97dee5-6bc7-40c3-b1cc-2af8e8efb117",
   "metadata": {},
   "source": [
    "Import R functions to score doublets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42b7709-1a4b-44eb-b8ff-947dbcb73454",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i data_mat -o doublet_score -o doublet_class\n",
    "\n",
    "library(Seurat)\n",
    "library(scater)\n",
    "library(scDblFinder)\n",
    "library(BiocParallel)\n",
    "\n",
    "\n",
    "set.seed(123)\n",
    "sce = scDblFinder(\n",
    "    SingleCellExperiment(\n",
    "        list(counts=data_mat),\n",
    "    ) \n",
    ")\n",
    "doublet_score = sce$scDblFinder.score\n",
    "doublet_class = sce$scDblFinder.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce5a952-f7e0-4db9-8d85-3c050885814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign scDblFinder scores into data:\n",
    "adata1.obs[\"scDblFinder_score\"] = doublet_score\n",
    "adata1.obs[\"scDblFinder_class\"] = doublet_class\n",
    "adata1.obs.scDblFinder_class.value_counts()\n",
    "\n",
    "del(doublet_score, doublet_class, data_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc201521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublet discrimination by scDblFinder\n",
    "# First extract matrix:\n",
    "data_mat = adata2.X.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d378b",
   "metadata": {},
   "source": [
    "Import R functions to score doublets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6c0895",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i data_mat -o doublet_score -o doublet_class\n",
    "\n",
    "library(Seurat)\n",
    "library(scater)\n",
    "library(scDblFinder)\n",
    "library(BiocParallel)\n",
    "\n",
    "\n",
    "set.seed(123)\n",
    "sce = scDblFinder(\n",
    "    SingleCellExperiment(\n",
    "        list(counts=data_mat),\n",
    "    ) \n",
    ")\n",
    "doublet_score = sce$scDblFinder.score\n",
    "doublet_class = sce$scDblFinder.class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4898b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign scDblFinder scores into data:\n",
    "adata2.obs[\"scDblFinder_score\"] = doublet_score\n",
    "adata2.obs[\"scDblFinder_class\"] = doublet_class\n",
    "adata2.obs.scDblFinder_class.value_counts()\n",
    "\n",
    "del(doublet_score, doublet_class, data_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444634e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore Plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3565c7",
   "metadata": {},
   "source": [
    "### Combine adata1 and adata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341c323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata1 and adata2 are from two GEMs, merge them together\n",
    "adata = sc.AnnData.concatenate(adata1, adata2, join = \"outer\", batch_key=\"gem\", batch_categories=[\"gem1\", \"gem2\"], index_unique=\"-\")\n",
    "print(adata)\n",
    "del(adata1, adata2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7906e-b8b8-4661-a777-ca0ff99100ce",
   "metadata": {},
   "source": [
    "### Create low-level filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c942eff-8d3a-4c3e-981c-67c94937a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Filters\n",
    "conditions = [\n",
    "    (adata.obs['predicted_doublet'] == True),\n",
    "    (adata.obs['scDblFinder_class'] == \"doublet\"),\n",
    "    (adata.obs['n_genes_by_counts'] < 1250),\n",
    "    (adata.obs['total_counts'] < 3000),\n",
    "    (adata.obs['pct_counts_mt'] > 5),\n",
    "    (adata.obs['pct_counts_mt'] <= 5) & (adata.obs['n_genes_by_counts'] >= 1250) & (adata.obs['total_counts'] >= 3000) & (adata.obs['scDblFinder_class'] == \"singlet\") & (adata.obs['predicted_doublet'] == False)]\n",
    "\n",
    "values = [ \n",
    "            'Doublet_Scrublet', \n",
    "            'Doublet_scDblFinder', \n",
    "            'Low_nFeature', \n",
    "            'Low_counts', \n",
    "            'High_MT', \n",
    "            'Pass']\n",
    "adata.obs['QC'] = np.select(conditions, values)\n",
    "adata.obs['QC'] = adata.obs['QC'].astype('category')\n",
    "\n",
    "# Filters\n",
    "adata.obs['QC'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b9f54a-7af0-4f5e-9d6b-5b28b5e1cf1c",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8be030-fdd2-406f-90e0-e5df271c3952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# High level filtering\n",
    "sc.pp.filter_cells(adata, min_genes=200)\n",
    "sc.pp.filter_genes(adata, min_cells=3)\n",
    "sc.pp.filter_genes(adata, min_counts=5)\n",
    "\n",
    "# Filtering\n",
    "adata = adata[adata.obs['QC'] == 'Pass', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ffa7f-4811-4c0e-8453-910ace5565cd",
   "metadata": {},
   "source": [
    "## Post-Filtering\n",
    "\n",
    "Check sample names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6bca61-55a2-4ef5-8519-0159e5262c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if sample labeling carried over\n",
    "print(adata)\n",
    "print(adata.obs['group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271408e0-0182-4a7e-95ee-a8ef20317020",
   "metadata": {},
   "source": [
    "Check the resulting quality metrics of the combined samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269ffca-a3ef-4ce9-96e3-bc8e1c856012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot combined QC metrics, grouped by sample (singlet filtered)\n",
    "\n",
    "sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts', 'pct_counts_mt'], groupby= \"group\", jitter=0.4, multi_panel=True)\n",
    "sc.pl.scatter(adata, x='total_counts', y='pct_counts_mt', color = \"group\", title = \"Post-filter All Samples\")\n",
    "sc.pl.scatter(adata, x='total_counts', y='n_genes_by_counts', color = \"group\", title = \"Post-filter All Samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a2e1af-b49d-452d-a60a-81998174d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot highest expressed genes per sample\n",
    "for group in sample_names:\n",
    "    plot = sc.pl.highest_expr_genes(adata[adata.obs.group == group, :], n_top=20, show = False)\n",
    "    plot.set_title(group + \" clean all samples\")\n",
    "# End of loop\n",
    "\n",
    "del(plot) # Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac9d136-9cb6-42ae-b9e2-18ac32686c8f",
   "metadata": {},
   "source": [
    "## Cell Cycle Regression\n",
    "\n",
    "These steps socre cell cycle effects and regress these effects out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b513b0-bab1-45f2-96d6-36b0ba481558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load S genes\n",
    "s_genes =  [x.strip() for x in open('../../source_data/mouse-s-gene-list.csv')]\n",
    "print(s_genes)\n",
    "\n",
    "# Load G2M genes\n",
    "g2m_genes =  [x.strip() for x in open('../../source_data/mouse-g2m-gene-list.csv')]\n",
    "print(g2m_genes)\n",
    "\n",
    "# Score cells for cell cycle\n",
    "sc.tl.score_genes_cell_cycle(adata, s_genes=s_genes, g2m_genes=g2m_genes) # Score filtered adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead08c8a-1634-4ed8-99a1-ebdac0744dc3",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Steps from here and onwards describe normalization steps prior to clustering analyses.\n",
    "\n",
    "The first step is to normalize cell counts to 20,000 reads per cell. We choose this number based on the Day 5 sample distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf2ef64-0ee0-4133-93c7-412330934c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize read counts\n",
    "sc.pp.normalize_total(adata, target_sum=2e4) # cell filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298e4c9d-8ee2-4d66-9711-17c1ee5d63ea",
   "metadata": {},
   "source": [
    "Then logarithmize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bfb403-e7b8-4c2d-b1e3-6b10b0c25f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to logarithmic scale\n",
    "sc.pp.log1p(adata) # cell filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e02d4-d51e-4ea1-8fbf-101da4991966",
   "metadata": {},
   "source": [
    "Stratify between MRE (adata) and RPE.\n",
    "\n",
    "Then identify highly-variable genes and plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5653b609-3f46-4bd5-a838-3d7089ff31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rescue data\n",
    "RPE   = adata[ (adata.obs.group != \"dAD\") & \n",
    "               (adata.obs.group != \"dID\") &\n",
    "               (adata.obs.group != \"dVWRPY\")].copy()\n",
    "\n",
    "# Identify variable genes\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "sc.pp.highly_variable_genes(RPE, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "# Plot variable genes\n",
    "sc.pl.highly_variable_genes(adata)\n",
    "sc.pl.highly_variable_genes(RPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe72cb49-4f43-4180-bc11-ecb5756de179",
   "metadata": {},
   "source": [
    "Set the raw attribute of AnnData as the normalized values, which is done prior to regression of count effects. This allows recovery of raw normalized data prior to correction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff033b5d-abc9-4f57-90f9-2e9db251d612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store raw data\n",
    "adata.raw = adata\n",
    "RPE.raw = RPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eaad2c-889e-4d9f-a600-f2d01fb135c3",
   "metadata": {},
   "source": [
    "Regress out effects of total counts per cell and the percentage of mitochondrial genes expressed. Scale the data to unit variance. In this step, I skipped filtering by highly variable genes that is present in the Scanpy tutorial, as I am interested in all genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f16a0c7-ba7c-4dd2-8b44-2310f3ea4d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regress out the effects of cell count and mitochondrial contamination\n",
    "sc.pp.regress_out(adata, ['total_counts', 'pct_counts_mt', 'S_score', 'G2M_score'])\n",
    "sc.pp.regress_out(RPE, ['total_counts', 'pct_counts_mt', 'S_score', 'G2M_score'])\n",
    "# Lastly, scale the data\n",
    "sc.pp.scale(adata)\n",
    "sc.pp.scale(RPE)\n",
    "# Check the resulting AnnData object\n",
    "print(\"MRE:\")\n",
    "print(adata)\n",
    "print(\"RPE:\")\n",
    "print(RPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1dad7e-31b9-4697-919d-6eb4fada135c",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "We can now do the preliminary steps prior to clustering analyses since the data is normalized and regressed. Start by identifying principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aa36e7-2e42-4211-bdfa-6a35dfef8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute principal components\n",
    "sc.tl.pca(adata, svd_solver='arpack', n_comps = 75)\n",
    "sc.tl.pca(RPE, svd_solver='arpack', n_comps = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af8771-93da-4586-b141-cfe2fd580ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "sc.pl.pca(adata, color='group', return_fig = True, title = \"Filtered MRE PCA\")\n",
    "sc.pl.pca(RPE, color='group', return_fig = True, title = \"Filtered RPE PCA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa986002-2cfc-4016-9bab-68e60a5b5d21",
   "metadata": {},
   "source": [
    "Identify the contribution of each principal component to variance through a Scree plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf8b3e-c89f-4f82-ab9a-9512e73d3373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Scree plot:\n",
    "sc.pl.pca_variance_ratio(adata, log=True, n_pcs = 60)\n",
    "sc.pl.pca_variance_ratio(RPE, log=True, n_pcs = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5310140e-dc02-4220-b785-e919a25cb083",
   "metadata": {},
   "source": [
    "## Save Data\n",
    "Procedures for saving data are outlined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa86e81-9ae2-4c2c-84f3-2ac0c1dca147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder for the saved data\n",
    "if savedata:\n",
    "\n",
    "    print(\"The AnnData outputs of this notebook will be saved in the h5ad/ folder.\")\n",
    "\n",
    "    # Save data to an AnnData file\n",
    "    print(\"MRE:\" + fn + sf + \"_MRE.h5ad\")\n",
    "    adata.write_h5ad(filename = \"../../h5ad/\" + fn + sf + \"_MRE.h5ad\", compression = \"gzip\", compression_opts = 9)\n",
    "    print(adata)\n",
    "    print(\"RPE:\" + fn + sf + \"_RPE.h5ad\")\n",
    "    RPE.write_h5ad(filename = \"../../h5ad/\" + fn + sf + \"_RPE.h5ad\", compression = \"gzip\", compression_opts = 9)\n",
    "    print(RPE)\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"Not saving the AnnData file!\")\n",
    "    \n",
    "# End of Notebook\n",
    "print(\"\\nNotebook Ends\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
